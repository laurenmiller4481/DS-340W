{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX_vxG73uPZU"
      },
      "outputs": [],
      "source": [
        "#import statements\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import operator\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.cluster import KMeans\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the in the dataset and checking the dataset read in properly\n",
        "reviews_with_prod_label = pd.read_csv('reviews_with_prod_label.csv')\n",
        "print(reviews_with_prod_label.head())\n",
        "print(reviews_with_prod_label.columns)\n",
        "print(reviews_with_prod_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioa8EAmhQlbh",
        "outputId": "26c6ef8e-70b2-4568-aa91-094290b71d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  index  review_rating  number_of_helpful  \\\n",
            "0           0      0            5.0                0.0   \n",
            "1           1      1            5.0                2.0   \n",
            "2           2      2            5.0                0.0   \n",
            "3           3      3            5.0                0.0   \n",
            "4           4      4            5.0                0.0   \n",
            "\n",
            "                                         review_body           review_title  \\\n",
            "0  JUST WHAT I THOUGHT IT WAS AND ORDER WENT SMOO...             Five Stars   \n",
            "1  After I saw the motion picture, Heaven is for ...  Wallet photo of Jesus   \n",
            "2  Great quality of image and prompty service, gr...             Five Stars   \n",
            "3     Loved them gave them out to sunday bible study             Five Stars   \n",
            "4       Arrived in perfect condition. No complaints.             Five Stars   \n",
            "\n",
            "  review_date  number_of_photos  product_ID  reviewer_ID  fake  \n",
            "0  2014-12-14                 0           0      2270578     0  \n",
            "1  2014-12-13                 0           0       499876     0  \n",
            "2  2014-12-08                 0           0      5066566     0  \n",
            "3  2014-12-05                 0           0      1571771     0  \n",
            "4  2014-11-29                 0           0      1787223     0  \n",
            "Index(['Unnamed: 0', 'index', 'review_rating', 'number_of_helpful',\n",
            "       'review_body', 'review_title', 'review_date', 'number_of_photos',\n",
            "       'product_ID', 'reviewer_ID', 'fake'],\n",
            "      dtype='object')\n",
            "(714556, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting review date to a datetime format\n",
        "reviews_with_prod_label['review_date'] = pd.to_datetime(reviews_with_prod_label['review_date'])\n",
        "\n",
        "#sort dataframe by product id and within product id sort by review date (earliest to latest)\n",
        "reviews_with_prod_label = reviews_with_prod_label.sort_values(['product_ID', 'review_date'])\n",
        "\n",
        "#get days between reviews for each review in product group\n",
        "#first group by product id, diff gets the difference between each row's review date and previous review data within the same product\n",
        "#then extract the nubmer of days from result using dt.days\n",
        "reviews_with_prod_label['days_between_reviews'] = (\n",
        "    reviews_with_prod_label.groupby('product_ID')['review_date']\n",
        "      .diff()\n",
        "      .dt.days\n",
        ")\n",
        "\n",
        "#fill days between reviews for first review of product with 0 instead of NA\n",
        "reviews_with_prod_label['days_between_reviews'] = reviews_with_prod_label['days_between_reviews'].fillna(0)\n",
        "\n",
        "#concatenate review title with review body into one feature\n",
        "reviews_with_prod_label[\"text\"] = reviews_with_prod_label[\"review_title\"].fillna(\"\") + \" \" + reviews_with_prod_label[\"review_body\"].fillna(\"\")\n",
        "#make all text lowercase\n",
        "reviews_with_prod_label[\"text\"] = reviews_with_prod_label[\"text\"].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "RVdajulKJy3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain review features for each product by grouping reviews by product id, then aggregating other columns to get features\n",
        "#ex. avg_review_rating comes from taking the mean of all of the reviews' ratings for each product\n",
        "reviews_metadata = reviews_with_prod_label.groupby([\"product_ID\"]).agg(\n",
        "    n_of_reviews = ('index', 'count'),\n",
        "    avg_review_rating = ('review_rating', 'mean'),\n",
        "    avg_days_between_reviews = ('days_between_reviews', 'mean'),\n",
        "    stdev_days_between_reviews = ('days_between_reviews', 'std'),\n",
        "    max_days_between_reviews = ('days_between_reviews', 'max'),\n",
        "    min_days_between_reviews = ('days_between_reviews', 'min'),\n",
        "    avg_helpful_reviews = ('number_of_helpful', lambda x: (x > 0).mean()),\n",
        "    avg_1star_reviews = ('review_rating', lambda x: (x == 1).mean()),\n",
        "    avg_5star_reviews = ('review_rating', lambda x: (x == 5).mean()),\n",
        "    avg_photo_reviews = ('number_of_photos', lambda x: (x > 0).mean()),\n",
        "    std_review_len = ('text', lambda x: x.apply(lambda y: len(y.split())).std())\n",
        ")\n",
        "\n",
        "#reset index\n",
        "reviews_metadata = reviews_metadata.reset_index()\n",
        "#add back in product id/fake label for each product\n",
        "reviews_metadata = reviews_metadata.merge(reviews_with_prod_label, on='product_ID', how='left')\n",
        "#remove duplicates of products, keep one instance of each product\n",
        "reviews_metadata = reviews_metadata.drop_duplicates(subset=['product_ID'])\n",
        "#keeping all columns related to metadata of reviews, with product id and label if buy fake reviews or not\n",
        "reviews_metadata = reviews_metadata[['index', 'product_ID', 'n_of_reviews', 'avg_review_rating', 'avg_days_between_reviews', 'stdev_days_between_reviews', 'max_days_between_reviews', 'min_days_between_reviews', 'avg_helpful_reviews', 'avg_1star_reviews', 'avg_5star_reviews', 'avg_photo_reviews', 'std_review_len', 'fake']]"
      ],
      "metadata": {
        "id": "GZxnOoKyHsk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define X as products, as will use products to uniquely identify cases for each type of data (review metadata, network features, text features)\n",
        "X = reviews_metadata[[\"product_ID\"]]\n",
        "#define y as fake label and corresponding product id so we can always use product id to rejoin to other dataframes\n",
        "y = reviews_metadata[[\"fake\", \"product_ID\"]]\n",
        "\n",
        "#80/20 train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F1XlWoijQK4",
        "outputId": "3ce84a54-e3f7-4817-de12-cc8b6b32922c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2726, 1)\n",
            "(682, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define training review text as text of reviews that belong to products whose product ids are in the training set of product ids\n",
        "X_train_text = reviews_with_prod_label[reviews_with_prod_label[\"product_ID\"].isin(X_train[\"product_ID\"])]\n",
        "#repeat same process for test text\n",
        "X_test_text = reviews_with_prod_label[reviews_with_prod_label[\"product_ID\"].isin(X_test[\"product_ID\"])]"
      ],
      "metadata": {
        "id": "i8iPVMGUomc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine text of all reviews in the same product id into one line of text associated with product id\n",
        "X_train_text_combined = (\n",
        "    X_train_text.groupby('product_ID')['text']\n",
        "    .apply(lambda x: ' '.join(x))\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "#repeat for test text\n",
        "X_test_text_combined = (\n",
        "    X_test_text.groupby('product_ID')['text']\n",
        "    .apply(lambda x: ' '.join(x))\n",
        "    .reset_index()\n",
        ")"
      ],
      "metadata": {
        "id": "4tuIw8sTsecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create tfidf object that that takes top 1000\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "#fit transform on the combined training text for each product\n",
        "X_train_text_tfidf = tfidf.fit_transform(X_train_text_combined[\"text\"])\n",
        "#transform the combined test text for each product\n",
        "X_test_text_tfidf = tfidf.transform(X_test_text_combined[\"text\"])\n",
        "#get feature names (words/numbers that where the top 1000 features)\n",
        "tfidf_features = tfidf.get_feature_names_out()\n",
        "\n",
        "#convert from sparse representation to dense representation\n",
        "X_train_text_tfidf = X_train_text_tfidf.toarray()\n",
        "X_test_text_tfidf = X_test_text_tfidf.toarray()\n",
        "\n",
        "#make tfidf representations dataframes with tfidf information as values, and features as column names\n",
        "X_train_text_tfidf = pd.DataFrame(X_train_text_tfidf, columns = tfidf_features)\n",
        "X_test_text_tfidf = pd.DataFrame(X_test_text_tfidf, columns = tfidf_features)"
      ],
      "metadata": {
        "id": "Vap-kupeo_Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate X_train_text_combined that has product id with training tfidf representation\n",
        "X_train_text_tfidf_pid = pd.concat([X_train_text_combined.reset_index(drop=True), X_train_text_tfidf.reset_index(drop=True)], axis=1)\n",
        "#repeat for X_test_text_combined and tfidf of test set\n",
        "X_test_text_tfidf_pid = pd.concat([X_test_text_combined.reset_index(drop=True), X_test_text_tfidf.reset_index(drop=True)], axis=1)\n",
        "\n",
        "#drop text column so only have product id and features of tfidf for each product in training set\n",
        "X_train_tfidf = X_train_text_tfidf_pid.drop(columns=['text'])\n",
        "#repeat for test set\n",
        "X_test_tfidf = X_test_text_tfidf_pid.drop(columns=['text'])"
      ],
      "metadata": {
        "id": "SLkxI4dTsLt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get X_train of reviews metadata by matching product ids in reviews metadata to product ids in X_train\n",
        "X_train_metadata = reviews_metadata[reviews_metadata[\"product_ID\"].isin(X_train[\"product_ID\"])]\n",
        "#repeat for X_test of reviews metadata\n",
        "X_test_metadata = reviews_metadata[reviews_metadata[\"product_ID\"].isin(X_test[\"product_ID\"])]\n",
        "\n",
        "#subset X_train_metdata to only keep features related to review metadata, except also keep product id\n",
        "X_train_metadata = X_train_metadata[['product_ID', 'n_of_reviews', 'avg_review_rating', 'avg_days_between_reviews', 'stdev_days_between_reviews', 'max_days_between_reviews', 'min_days_between_reviews', 'avg_helpful_reviews', 'avg_1star_reviews', 'avg_5star_reviews', 'avg_photo_reviews', 'std_review_len']]\n",
        "#repeat for X_test_metadata\n",
        "X_test_metadata = X_test_metadata[['product_ID', 'n_of_reviews', 'avg_review_rating', 'avg_days_between_reviews', 'stdev_days_between_reviews', 'max_days_between_reviews', 'min_days_between_reviews', 'avg_helpful_reviews', 'avg_1star_reviews', 'avg_5star_reviews', 'avg_photo_reviews', 'std_review_len']]"
      ],
      "metadata": {
        "id": "CA2KExmauCQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZJbOXGl_ubo"
      },
      "outputs": [],
      "source": [
        "def weighted_projected_graph(B, nodes, ratio=False):\n",
        "  if B.is_directed():\n",
        "    pred = B.pred\n",
        "    G = nx.DiGraph()\n",
        "  else:\n",
        "    pred = B.adj\n",
        "    G = nx.Graph()\n",
        "  G.graph.update(B.graph)\n",
        "  G.add_nodes_from((n, B.nodes[n]) for n in nodes)\n",
        "  n_top = float(len(B) - len(nodes))\n",
        "  nodes_checked = []\n",
        "  for u in nodes:\n",
        "    nodes_checked.append(u)\n",
        "    unbrs = set(B[u])\n",
        "    nbrs2 = {n for nbr in unbrs for n in B[nbr]} - set(nodes_checked)\n",
        "    for v in nbrs2:\n",
        "      vnbrs = set(pred[v])\n",
        "      common = unbrs & vnbrs\n",
        "      if not ratio:\n",
        "        weight = len(common)\n",
        "      else:\n",
        "        weight = len(common) / n_top\n",
        "      G.add_edge(u, v, weight=weight)\n",
        "  return G\n",
        "\n",
        "def obtain_network_features(reviews):\n",
        "  # initializing the product-level data\n",
        "  df = pd.DataFrame({\"product_ID\": reviews.product_ID.unique()})\n",
        "\n",
        "  # building the bipartite product-reviewer graph\n",
        "  B = nx.Graph()\n",
        "  B.add_nodes_from(reviews.reviewer_ID, bipartite=0)\n",
        "  B.add_nodes_from(reviews.product_ID, bipartite=1)\n",
        "  B.add_edges_from([(row['reviewer_ID'], row['product_ID']) for idx, row in reviews.iterrows()])\n",
        "\n",
        "  # building the product projected graph\n",
        "  P = weighted_projected_graph(B, reviews.product_ID.unique())\n",
        "\n",
        "  w_degree = nx.degree(P, weight='weight')\n",
        "  cc = nx.clustering(P)\n",
        "  pr = nx.pagerank(P, alpha=0.85)\n",
        "  eig_cent = nx.eigenvector_centrality(P, max_iter=500)\n",
        "\n",
        "  # creating the features data\n",
        "  df['w_degree'] = [w_degree[i] for i in df.product_ID]\n",
        "  df['clustering_coef'] = [cc[i] for i in df.product_ID]\n",
        "  df['pagerank'] = [pr[i] for i in df.product_ID]\n",
        "  df['eigenvector_cent'] = [eig_cent[i] for i in df.product_ID]\n",
        "  return df\n",
        "\n",
        "#define network features for training set of products and reviwers in training set of reviews\n",
        "X_train_network = obtain_network_features(X_train_text)\n",
        "#repeat for test set\n",
        "X_test_network = obtain_network_features(X_test_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop duplicates of network featuers so only have one instance network features for each product in the training set\n",
        "X_train_with_network = X_train_network.drop_duplicates(subset=['product_ID'])\n",
        "#do the same for the set of products in the testing set\n",
        "X_test_with_network = X_test_network.drop_duplicates(subset=['product_ID'])\n",
        "\n",
        "#subset X_train_with_network to include only network features and product id\n",
        "X_train_with_network = X_train_with_network[['product_ID', 'w_degree', 'clustering_coef', 'pagerank', 'eigenvector_cent']]\n",
        "#repeat for text set\n",
        "X_test_with_network = X_test_with_network[['product_ID', 'w_degree', 'clustering_coef', 'pagerank', 'eigenvector_cent']]"
      ],
      "metadata": {
        "id": "xrY1CvmOozTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining network, reviews, and text features\n",
        "network_features = ['pagerank', 'w_degree', 'clustering_coef', 'eigenvector_cent']\n",
        "\n",
        "review_features = ['n_of_reviews','avg_review_rating',\n",
        "                   'avg_days_between_reviews', 'stdev_days_between_reviews',\n",
        "                   'max_days_between_reviews', 'min_days_between_reviews',\n",
        "                   'avg_helpful_reviews', 'avg_1star_reviews', 'avg_5star_reviews', 'avg_photo_reviews', 'std_review_len']\n",
        "\n",
        "text_features = tfidf_features.tolist()"
      ],
      "metadata": {
        "id": "kCMiOCoaFYFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge all features subsets together for training set based on product id\n",
        "X_train_all_features = pd.merge(pd.merge(X_train_metadata, X_train_with_network, on='product_ID', how='inner'), X_train_tfidf, on='product_ID', how='inner')\n",
        "#repeat for testing set\n",
        "X_test_all_features = pd.merge(pd.merge(X_test_metadata, X_test_with_network, on='product_ID', how='inner'), X_test_tfidf, on='product_ID', how='inner')\n",
        "\n",
        "#create standard scaled object\n",
        "scaler = StandardScaler()\n",
        "#fit and transform all features for training set, excluding product id\n",
        "X_train_all_features_scaled = scaler.fit_transform(X_train_all_features[network_features + review_features + text_features])\n",
        "#transform all features for test set, excluding product id\n",
        "X_test_all_features_scaled = scaler.transform(X_test_all_features[network_features + review_features + text_features])\n",
        "\n",
        "#transform scaled array to dataframe with sacled values and features names as column names for training set\n",
        "X_train_all_features_scaled = pd.DataFrame(X_train_all_features_scaled, columns = network_features + review_features + text_features)\n",
        "#repeat for test set\n",
        "X_test_all_features_scaled = pd.DataFrame(X_test_all_features_scaled, columns = network_features + review_features + text_features)\n",
        "\n",
        "#add back in product id to training set (unscaled)\n",
        "X_train_all_features_scaled[\"product_ID\"] = X_train_all_features[\"product_ID\"]\n",
        "#repeat for test set\n",
        "X_test_all_features_scaled[\"product_ID\"] = X_test_all_features[\"product_ID\"]"
      ],
      "metadata": {
        "id": "4aS7vBirrXXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get labels from y_train, as y_train has labels and product id\n",
        "y_train_labels = y_train[[\"fake\"]]\n",
        "#repeat for y_test\n",
        "y_test_labels = y_test[[\"fake\"]]\n",
        "\n",
        "#flatten dimensionality of y_train_labels so just array of values (prep for ml model inputs)\n",
        "y_train_labels = y_train_labels.values.ravel()\n",
        "#repeat for y_test_labels\n",
        "y_test_labels = y_test_labels.values.ravel()"
      ],
      "metadata": {
        "id": "m_BVFurKHZ1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Supervised"
      ],
      "metadata": {
        "id": "pQIGmItMFbOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_building(X_train, y_train, X_test, y_test, model):\n",
        "\t#general function to evaluate model performance on model and data passed in\n",
        "\n",
        "\t#fit model\n",
        "\tmodel.fit(X_train, y_train)\n",
        "\n",
        "\t#obtain label predictions on test set\n",
        "\ty_pred = model.predict(X_test)\n",
        "\t#get confusion matrix\n",
        "\tcm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
        "\t#get probability predictions using model on test set\n",
        "\tprobs = model.predict_proba(X_test)[:,1]\n",
        "\t#get accuracy, precision, recall, f1\n",
        "\taccuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
        "\tprint(\"Accuracy\", accuracy_score)\n",
        "\tprecision = metrics.precision_score(y_test, y_pred, zero_division = 0)\n",
        "\tprint(\"Precision\", precision)\n",
        "\trecall = metrics.recall_score(y_test, y_pred, zero_division = 0)\n",
        "\tprint(\"Recall\", recall)\n",
        "\tf1 = metrics.f1_score(y_test, y_pred, zero_division = 0)\n",
        "\tprint(\"F1 Score\", f1)\n",
        "\tprint(\"\\n\")\n",
        "\n",
        "\t#print out metrics\n",
        "\tprint(\"AUC, Accuracy, TN, TP, F1 Score\")\n",
        "\tprint(\"{}, {}, {}, {}, {}\".format(metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1]),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  sum(cm.diagonal()) / X_test.shape[0],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  cm[0,0] / sum(cm[0,:]),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  cm[1,1] / sum(cm[1,:]),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  metrics.f1_score(y_test, y_pred, average='weighted')))\n",
        "\t#return predicted probabilties on test set using model passed in\n",
        "\treturn probs"
      ],
      "metadata": {
        "id": "O2YeGe9ZGBns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_results(X_train, X_test, features=None):\n",
        "  #subset training and test set to features want to use for this function call\n",
        "  X_train = X_train[features]\n",
        "  X_test = X_test[features]\n",
        "\n",
        "  #build loigistic regression model and evaluate on test set\n",
        "  print(\"=\"*10 + \"Logistic Regression\" + \"=\"*10)\n",
        "  model = LogisticRegression(max_iter=400)\n",
        "  model_building(X_train, y_train_labels, X_test, y_test_labels, model)\n",
        "\n",
        "  #build random forest classifier and evaluate on test set\n",
        "  print(\"=\"*10 + \"Random Forest\" + \"=\"*10)\n",
        "  model = RandomForestClassifier(random_state=42,\n",
        "                                 n_estimators=100,\n",
        "\t                               min_samples_leaf=3,\n",
        "\t                               min_samples_split=6,\n",
        "\t                               max_features='sqrt',\n",
        "\t                               max_depth=40,\n",
        "\t                               bootstrap=True,\n",
        "\t                               n_jobs=-1)\n",
        "  model_building(X_train, y_train_labels, X_test, y_test_labels, model)\n",
        "\n",
        "  #get feature importance from random forest classifier\n",
        "  print(\"=\"*10 + \"RF Feature Importance\" + \"=\"*10)\n",
        "  imps = model.feature_importances_\n",
        "  feat_imp = {features[i]: imps[i] for i in range(len(features))}\n",
        "\n",
        "  #if more than 100 features, only output top 50 features and their importance\n",
        "  if len(features) > 100:\n",
        "    print(sorted(feat_imp.items(), key=operator.itemgetter(1), reverse=True)[:50])\n",
        "  #if elss than 100 features, outupt all features and their importance\n",
        "  else:\n",
        "    print(sorted(feat_imp.items(), key=operator.itemgetter(1), reverse=True))\n",
        "\n",
        "  #build SVC linear classifier and evaluate on test set\n",
        "  print(\"=\"*10 + \"SVC Linear\" + \"=\"*10)\n",
        "  model = SVC(kernel='linear', probability=True)\n",
        "  model_building(X_train, y_train_labels, X_test, y_test_labels, model)\n",
        "\n",
        "  #build xg boost classifier and evaluate on test set\n",
        "  print(\"=\"*10 + \"XGBoost\" + \"=\"*10)\n",
        "  model = xgb.XGBClassifier()\n",
        "  model_building(X_train, y_train_labels, X_test, y_test_labels, model)\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "RsTw4vqHAf6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call set of models on scaled review features\n",
        "classification_results(X_train_all_features_scaled, X_test_all_features_scaled, features=review_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQaYu-jVE3xa",
        "outputId": "730564c9-980d-47d2-c284-92c53c4aaa3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Logistic Regression==========\n",
            "Accuracy 0.592375366568915\n",
            "Precision 0.28\n",
            "Recall 0.026217228464419477\n",
            "F1 Score 0.04794520547945205\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.48347998736519116, 0.592375366568915, 0.9566265060240964, 0.026217228464419477, 0.46947228915879363\n",
            "==========Random Forest==========\n",
            "Accuracy 0.5557184750733137\n",
            "Precision 0.4117647058823529\n",
            "Recall 0.3146067415730337\n",
            "F1 Score 0.35668789808917195\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5078200442218312, 0.5557184750733137, 0.7108433734939759, 0.3146067415730337, 0.5416771241774561\n",
            "==========RF Feature Importance==========\n",
            "[('std_review_len', np.float64(0.11478019642224352)), ('avg_review_rating', np.float64(0.10403696987092186)), ('avg_1star_reviews', np.float64(0.10380726195763872)), ('avg_5star_reviews', np.float64(0.10308085108255806)), ('stdev_days_between_reviews', np.float64(0.10307972614375453)), ('avg_days_between_reviews', np.float64(0.10131923580170062)), ('max_days_between_reviews', np.float64(0.10127734261813234)), ('avg_helpful_reviews', np.float64(0.09998912593717278)), ('n_of_reviews', np.float64(0.09794708631655567)), ('avg_photo_reviews', np.float64(0.07068220384932199)), ('min_days_between_reviews', np.float64(0.0))]\n",
            "==========SVC Linear==========\n",
            "Accuracy 0.6085043988269795\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5082351879427823, 0.6085043988269795, 1.0, 0.0, 0.46039986419908197\n",
            "==========XGBoost==========\n",
            "Accuracy 0.5278592375366569\n",
            "Precision 0.4007220216606498\n",
            "Recall 0.4157303370786517\n",
            "F1 Score 0.40808823529411764\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5062948422905104, 0.5278592375366569, 0.6, 0.4157303370786517, 0.5293198595152244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call set of models on scaled network features\n",
        "classification_results(X_train_all_features_scaled, X_test_all_features_scaled, features=network_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU_x5KxeCUjJ",
        "outputId": "6cad6edf-abc6-4994-e259-1643ac252bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Logistic Regression==========\n",
            "Accuracy 0.6085043988269795\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.4660845629709851, 0.6085043988269795, 1.0, 0.0, 0.46039986419908197\n",
            "==========Random Forest==========\n",
            "Accuracy 0.5850439882697948\n",
            "Precision 0.4375\n",
            "Recall 0.20973782771535582\n",
            "F1 Score 0.28354430379746837\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5042191236857543, 0.5850439882697948, 0.8265060240963855, 0.20973782771535582, 0.5417948075250545\n",
            "==========RF Feature Importance==========\n",
            "[('eigenvector_cent', np.float64(0.27859043760824637)), ('pagerank', np.float64(0.2744448176320625)), ('clustering_coef', np.float64(0.26668286171537386)), ('w_degree', np.float64(0.18028188304431725))]\n",
            "==========SVC Linear==========\n",
            "Accuracy 0.6085043988269795\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5198005505166734, 0.6085043988269795, 1.0, 0.0, 0.46039986419908197\n",
            "==========XGBoost==========\n",
            "Accuracy 0.5953079178885631\n",
            "Precision 0.4482758620689655\n",
            "Recall 0.14606741573033707\n",
            "F1 Score 0.22033898305084745\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5293894679842968, 0.5953079178885631, 0.8843373493975903, 0.14606741573033707, 0.5284817710858019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call set of models on what paper thinks is top two network features\n",
        "classification_results(X_train_all_features_scaled, X_test_all_features_scaled, features=['eigenvector_cent', 'clustering_coef'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWmfr9zhFFQ3",
        "outputId": "49bc0d13-4512-42d3-c5e3-9ac93a48af87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Logistic Regression==========\n",
            "Accuracy 0.6055718475073314\n",
            "Precision 0.45454545454545453\n",
            "Recall 0.03745318352059925\n",
            "F1 Score 0.06920415224913495\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5077794323360858, 0.6055718475073314, 0.9710843373493976, 0.03745318352059925, 0.48332990765778894\n",
            "==========Random Forest==========\n",
            "Accuracy 0.5293255131964809\n",
            "Precision 0.3761467889908257\n",
            "Recall 0.30711610486891383\n",
            "F1 Score 0.33814432989690724\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.49036595821488205, 0.5293255131964809, 0.672289156626506, 0.30711610486891383, 0.5186680865961634\n",
            "==========RF Feature Importance==========\n",
            "[('eigenvector_cent', np.float64(0.5142366728943509)), ('clustering_coef', np.float64(0.48576332710564907))]\n",
            "==========SVC Linear==========\n",
            "Accuracy 0.6085043988269795\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.4924552141148866, 0.6085043988269795, 1.0, 0.0, 0.46039986419908197\n",
            "==========XGBoost==========\n",
            "Accuracy 0.5058651026392962\n",
            "Precision 0.36328125\n",
            "Recall 0.34831460674157305\n",
            "F1 Score 0.35564053537284895\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.4957808763142457, 0.5058651026392962, 0.6072289156626506, 0.34831460674157305, 0.5039002153147647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call set of models on review and network features\n",
        "classification_results(X_train_all_features_scaled, X_test_all_features_scaled, features=review_features + network_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4HLB-L9FPSt",
        "outputId": "9100e148-284a-428c-9b76-811f4237a6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Logistic Regression==========\n",
            "Accuracy 0.5997067448680352\n",
            "Precision 0.3125\n",
            "Recall 0.018726591760299626\n",
            "F1 Score 0.0353356890459364\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.4720545101755336, 0.5997067448680352, 0.9734939759036144, 0.018726591760299626, 0.46866406678168293\n",
            "==========Random Forest==========\n",
            "Accuracy 0.5557184750733137\n",
            "Precision 0.4072164948453608\n",
            "Recall 0.2958801498127341\n",
            "F1 Score 0.34273318872017355\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.48469834393754796, 0.5557184750733137, 0.7228915662650602, 0.2958801498127341, 0.5385003954456513\n",
            "==========RF Feature Importance==========\n",
            "[('std_review_len', np.float64(0.08060696261899274)), ('clustering_coef', np.float64(0.07742946411016653)), ('avg_days_between_reviews', np.float64(0.07727446767344669)), ('avg_5star_reviews', np.float64(0.07490643917021049)), ('avg_1star_reviews', np.float64(0.07446406747578954)), ('max_days_between_reviews', np.float64(0.07338658646051058)), ('avg_review_rating', np.float64(0.0730099668948618)), ('eigenvector_cent', np.float64(0.07260744282496082)), ('stdev_days_between_reviews', np.float64(0.07228797882605965)), ('avg_helpful_reviews', np.float64(0.07204707945341815)), ('pagerank', np.float64(0.07142059461369947)), ('n_of_reviews', np.float64(0.06686109677402646)), ('w_degree', np.float64(0.06094574491884201)), ('avg_photo_reviews', np.float64(0.05275210818501519)), ('min_days_between_reviews', np.float64(0.0))]\n",
            "==========SVC Linear==========\n",
            "Accuracy 0.6085043988269795\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5174585984386986, 0.6085043988269795, 1.0, 0.0, 0.46039986419908197\n",
            "==========XGBoost==========\n",
            "Accuracy 0.5146627565982405\n",
            "Precision 0.38321167883211676\n",
            "Recall 0.39325842696629215\n",
            "F1 Score 0.38817005545286504\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.4963855421686747, 0.5146627565982405, 0.5927710843373494, 0.39325842696629215, 0.5157386361948596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call set of models on text features\n",
        "classification_results(X_train_all_features_scaled, X_test_all_features_scaled, features = text_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6FQDQehFWy4",
        "outputId": "cadab3ec-4e7c-445c-d2da-be0199361e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Logistic Regression==========\n",
            "Accuracy 0.49266862170087977\n",
            "Precision 0.3696369636963696\n",
            "Recall 0.41947565543071164\n",
            "F1 Score 0.3929824561403509\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5061730066332747, 0.49266862170087977, 0.5397590361445783, 0.41947565543071164, 0.4971883974693672\n",
            "==========Random Forest==========\n",
            "Accuracy 0.5733137829912024\n",
            "Precision 0.3723404255319149\n",
            "Recall 0.13108614232209737\n",
            "F1 Score 0.19390581717451524\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5120572176345833, 0.5733137829912024, 0.8578313253012049, 0.13108614232209737, 0.5078725286678855\n",
            "==========RF Feature Importance==========\n",
            "[('came', np.float64(0.0026631307067331716)), ('off', np.float64(0.0024532731472602567)), ('expected', np.float64(0.0024078506441855933)), ('did', np.float64(0.0023927343601812157)), ('our', np.float64(0.002312392853852551)), ('after', np.float64(0.002295352495242248)), ('through', np.float64(0.002243966766814618)), ('from', np.float64(0.0022190445175629477)), ('is', np.float64(0.0021515478202703536)), ('again', np.float64(0.002146503444969373)), ('two', np.float64(0.0020598439375503503)), ('however', np.float64(0.0020555222738873587)), ('your', np.float64(0.0020456355173449113)), ('small', np.float64(0.00204107704182345)), ('easy', np.float64(0.002025585303782962)), ('thing', np.float64(0.002025484707054902)), ('bought', np.float64(0.0020204297836486965)), ('do', np.float64(0.0020198979365029955)), ('plastic', np.float64(0.0020117644947189183)), ('at', np.float64(0.0020015559310719066)), ('right', np.float64(0.001976677317855987)), ('come', np.float64(0.0019740638137859365)), ('years', np.float64(0.0019581546958542567)), ('left', np.float64(0.001957457152397804)), ('having', np.float64(0.00194992670051237)), ('worth', np.float64(0.0019470428377735638)), ('side', np.float64(0.001944887290196602)), ('still', np.float64(0.0019437152879733805)), ('than', np.float64(0.0019408696991608096)), ('all', np.float64(0.001938785038295544)), ('most', np.float64(0.0019353933940107564)), ('reviews', np.float64(0.001933764151386422)), ('will', np.float64(0.0019282899122811965)), ('over', np.float64(0.0019130770395965851)), ('super', np.float64(0.0019105200535933758)), ('doesn', np.float64(0.0019104879907555039)), ('for', np.float64(0.0019015101782143622)), ('because', np.float64(0.0019008565973315074)), ('don', np.float64(0.0018952547440620735)), ('three', np.float64(0.0018897258231610036)), ('enough', np.float64(0.0018890405801597035)), ('that', np.float64(0.001882149969818359)), ('few', np.float64(0.0018815967249466666)), ('wish', np.float64(0.0018775746187946753)), ('good', np.float64(0.0018655846525824575)), ('being', np.float64(0.001862519149819499)), ('had', np.float64(0.0018558708610858438)), ('clear', np.float64(0.001852306822653938)), ('with', np.float64(0.0018505749855841091)), ('value', np.float64(0.0018486911906354262))]\n",
            "==========SVC Linear==========\n",
            "Accuracy 0.4897360703812317\n",
            "Precision 0.3776435045317221\n",
            "Recall 0.4681647940074906\n",
            "F1 Score 0.4180602006688963\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5039709399395335, 0.4897360703812317, 0.5036144578313253, 0.4681647940074906, 0.4957246547958393\n",
            "==========XGBoost==========\n",
            "Accuracy 0.5571847507331378\n",
            "Precision 0.4146341463414634\n",
            "Recall 0.31835205992509363\n",
            "F1 Score 0.3601694915254237\n",
            "\n",
            "\n",
            "AUC, Accuracy, TN, TP, F1 Score\n",
            "0.5173548125084608, 0.5571847507331378, 0.7108433734939759, 0.31835205992509363, 0.5434908650034537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering - Into Supervised Learning"
      ],
      "metadata": {
        "id": "Sm-Br4KYFeo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set k for number of clusters want\n",
        "k_clusters = 5\n",
        "#define k means clustering object\n",
        "kmeans = KMeans(n_clusters=k_clusters, random_state=42)\n",
        "#fit k means object to X_train features\n",
        "kmeans.fit(X_train_all_features_scaled)\n",
        "\n",
        "#get training labels from k means\n",
        "train_labels = kmeans.labels_\n",
        "#predict labels for X_test using k means and store labels\n",
        "test_labels = kmeans.predict(X_test_all_features_scaled)\n",
        "\n",
        "#add cluster labels to train/test set as column\n",
        "X_train_all_features_scaled['cluster_ID'] = train_labels + 1\n",
        "X_test_all_features_scaled['cluster_ID'] = test_labels + 1\n",
        "#sort test set in ascending order based on cluster id\n",
        "X_test_all_features_scaled = X_test_all_features_scaled.sort_values('cluster_ID')\n",
        "\n",
        "print(\"Number of products in each cluster:\", X_train_all_features_scaled.groupby('cluster_ID')['product_ID'].count())\n",
        "print(\"\\n\")\n",
        "\n",
        "#define lists to store metrics for each cluster to average at the end\n",
        "accuracy_score_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "pred_probs = []\n",
        "\n",
        "#iterate through each cluster\n",
        "for i in range(k_clusters):\n",
        "  #print which cluster working on\n",
        "  print(\"Cluster\", (i + 1))\n",
        "  #get training data and testing data that belong to this cluster based on k means labels\n",
        "  X_train_cluster = X_train_all_features_scaled[train_labels == i]\n",
        "  X_test_cluster = X_test_all_features_scaled[test_labels == i]\n",
        "\n",
        "  #get corresponding y_train and y_test labels based on matching X_training/X_test product ids to product ids of y_train/y_test\n",
        "  y_train_cluster = y_train[y_train['product_ID'].isin(X_train_cluster['product_ID'])]\n",
        "  y_test_cluster = y_test[y_test['product_ID'].isin(X_test_cluster['product_ID'])]\n",
        "\n",
        "  #subset y_train for this cluster to only have labels (fake)\n",
        "  y_train_cluster = y_train_cluster[['fake']]\n",
        "  #repeat for y_test for this cluster\n",
        "  y_test_cluster = y_test_cluster[['fake']]\n",
        "\n",
        "  #flatten dimensionality of y_train so just array of values of labels (prep for ml model inputs)\n",
        "  y_train_cluster = y_train_cluster.values.ravel()\n",
        "  #repeat for y_test\n",
        "  y_test_cluster = y_test_cluster.values.ravel()\n",
        "\n",
        "  #create random forest classifier object\n",
        "  model = RandomForestClassifier(random_state=42,\n",
        "\t                               n_estimators=1200,\n",
        "\t                               min_samples_leaf=3,\n",
        "\t                               min_samples_split=6,\n",
        "\t                               max_features='sqrt',\n",
        "\t                               max_depth=40,\n",
        "\t                               bootstrap=True,\n",
        "\t                               n_jobs=-1)\n",
        "\n",
        "  #fit model to X_train and y_train for this cluster\n",
        "  model.fit(X_train_cluster, y_train_cluster)\n",
        "  #predict labels based on on X_test data for this cluster\n",
        "  y_pred = model.predict(X_test_cluster)\n",
        "  #predict probabiltiy that product buy fake reviews\n",
        "  y_pred_probs = model.predict_proba(X_test_cluster)[:,1]\n",
        "  #append predicted probabilties to list, so have all predicted probabilties across entire test set at end of loop\n",
        "  pred_probs.append(y_pred_probs)\n",
        "  #number of products identified as buying fake reviews with different thresholds\n",
        "  print(\"The number of products identified as products that buy fake reviews with a threshold of 0.5:\", sum(y_pred_probs >= 0.5))\n",
        "  print(\"The number of products identified as products that buy fake reviews with a threshold of 0.6:\", sum(y_pred_probs >= 0.6))\n",
        "  print(\"The number of products identified as products that buy fake reviews with a threshold of 0.7:\", sum(y_pred_probs >= 0.7))\n",
        "\n",
        "\n",
        "  #get accuracy for this cluster, append accuracy to accuracy list that will contain accuracy values for each cluster at the end of the loop\n",
        "  accuracy_score = metrics.accuracy_score(y_test_cluster, y_pred)\n",
        "  #append accuracy to accuracy list that will contain accuracy values for each cluster at the end of the loop\n",
        "  accuracy_score_lst.append(accuracy_score)\n",
        "  #print out accuracy for this cluster\n",
        "  print(\"Accuracy\", accuracy_score)\n",
        "  #repeat steps for precision\n",
        "  precision = metrics.precision_score(y_test_cluster, y_pred, zero_division = 0)\n",
        "  precision_lst.append(precision)\n",
        "  print(\"Precision\", precision)\n",
        "  #repeat steps for recall\n",
        "  recall = metrics.recall_score(y_test_cluster, y_pred, zero_division = 0)\n",
        "  recall_lst.append(recall)\n",
        "  print(\"Recall\", recall)\n",
        "  #repeat steps for f1\n",
        "  f1 = metrics.f1_score(y_test_cluster, y_pred, zero_division = 0)\n",
        "  f1_lst.append(f1)\n",
        "  print(\"F1 Score\", f1)\n",
        "  #repeat steps for AUC\n",
        "  auc = metrics.roc_auc_score(y_test_cluster, model.predict_proba(X_test_cluster)[:,1])\n",
        "  auc_lst.append(auc)\n",
        "  print(\"AUC\", auc)\n",
        "  print(\"***********\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "#print average accuracy across clusters by averaging values in accuracy_score_lst\n",
        "#repeat for all metrics\n",
        "print(\"\\n\")\n",
        "print(\"Average Across all Clusters\")\n",
        "average_accuracy = sum(accuracy_score_lst) / len(accuracy_score_lst)\n",
        "print(\"Accuracy\", average_accuracy)\n",
        "average_precision = sum(precision_lst) / len(precision_lst)\n",
        "print(\"Precision\", average_precision)\n",
        "average_recall = sum(recall_lst) / len(recall_lst)\n",
        "print(\"Recall\", average_recall)\n",
        "average_f1 = sum(f1_lst) / len(f1_lst)\n",
        "print(\"F1 Score\", average_f1)\n",
        "average_auc = sum(auc_lst) / len(auc_lst)\n",
        "print(\"AUC\", average_auc)"
      ],
      "metadata": {
        "id": "igLZBE-sshIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965dea3c-6944-4ac6-a36d-d285d458fc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of products in each cluster: cluster_ID\n",
            "1    537\n",
            "2    567\n",
            "3    518\n",
            "4    563\n",
            "5    541\n",
            "Name: product_ID, dtype: int64\n",
            "\n",
            "\n",
            "Cluster 1\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.5: 13\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.6: 0\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.7: 0\n",
            "Accuracy 0.8297872340425532\n",
            "Precision 0.07692307692307693\n",
            "Recall 0.07692307692307693\n",
            "F1 Score 0.07692307692307693\n",
            "AUC 0.49459134615384615\n",
            "***********\n",
            "\n",
            "\n",
            "Cluster 2\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.5: 122\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.6: 122\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.7: 121\n",
            "Accuracy 0.22950819672131148\n",
            "Precision 0.22950819672131148\n",
            "Recall 1.0\n",
            "F1 Score 0.37333333333333335\n",
            "AUC 0.5113981762917933\n",
            "***********\n",
            "\n",
            "\n",
            "Cluster 3\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.5: 0\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.6: 0\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.7: 0\n",
            "Accuracy 0.5308641975308642\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "AUC 0.5299877600979193\n",
            "***********\n",
            "\n",
            "\n",
            "Cluster 4\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.5: 117\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.6: 51\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.7: 1\n",
            "Accuracy 0.5867768595041323\n",
            "Precision 0.5897435897435898\n",
            "Recall 0.971830985915493\n",
            "F1 Score 0.7340425531914894\n",
            "AUC 0.508169014084507\n",
            "***********\n",
            "\n",
            "\n",
            "Cluster 5\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.5: 0\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.6: 0\n",
            "The number of products identified as products that buy fake reviews with a threshold of 0.7: 0\n",
            "Accuracy 0.41911764705882354\n",
            "Precision 0.0\n",
            "Recall 0.0\n",
            "F1 Score 0.0\n",
            "AUC 0.3961803242282923\n",
            "***********\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Average Across all Clusters\n",
            "Accuracy 0.519210826971537\n",
            "Precision 0.17923497267759564\n",
            "Recall 0.409750812567714\n",
            "F1 Score 0.23685979268957996\n",
            "AUC 0.48806532417127163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten arrays into one list\n",
        "pred_probs = np.concatenate(pred_probs).tolist()\n",
        "#add list of predictions to X_test as column\n",
        "X_test_all_features_scaled['p_fake'] = pred_probs\n",
        "#create pivot table of mean values for each feature across cluster ids\n",
        "#p_fake is the number of products identified as products that buy fake reviews based on a thershold of 0.5 in each cluster\n",
        "clusters_pt = X_test_all_features_scaled.pivot_table(index='cluster_ID', aggfunc={\n",
        "                                'clustering_coef': 'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'eigenvector_cent': 'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'avg_photo_reviews': 'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'w_degree': 'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'n_of_reviews': 'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'max_days_between_reviews':'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'pagerank':'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'avg_5star_reviews':'mean',\n",
        "                                'avg_days_between_reviews':'mean',\n",
        "                                'stdev_days_between_reviews':'mean',\n",
        "                                'avg_review_rating':'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'std_review_len':'mean',\n",
        "                                'avg_1star_reviews':'mean',\n",
        "                                'avg_helpful_reviews':'mean',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'min_days_between_reviews':'mean',\n",
        "                                'product_ID':'count',\n",
        "                                'p_fake':lambda x:(x>=0.5).sum(),}\n",
        ")\n",
        "\n",
        "#standardize values in pivot table by z score\n",
        "clusters_pt[review_features + network_features] = scipy.stats.zscore(clusters_pt[review_features + network_features])\n",
        "#reorder features based on parent paper importance scores in the random forest classifier\n",
        "clusters_pt = clusters_pt.reindex(['clustering_coef','eigenvector_cent',\n",
        "\t\t\t\t\t\t\t\t\t'avg_photo_reviews','w_degree','n_of_reviews','max_days_between_reviews',\n",
        "\t\t\t\t\t\t\t\t\t'pagerank','avg_5star_reviews','avg_days_between_reviews',\n",
        "\t\t\t\t\t\t\t\t\t'stdev_days_between_reviews','avg_review_rating','std_review_len',\n",
        "\t\t\t\t\t\t\t\t\t'avg_1star_reviews','avg_helpful_reviews','min_days_between_reviews','product_ID','p_fake'], axis=1)\n",
        "clusters_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "v7J7tUYACBSa",
        "outputId": "04a0366c-04e2-4bcf-94ea-6f3c15a685e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            clustering_coef  eigenvector_cent  avg_photo_reviews  w_degree  \\\n",
              "cluster_ID                                                                   \n",
              "1                 -0.467836          0.301230           1.761530  0.156124   \n",
              "2                 -1.490958         -1.222219           0.104735 -0.672853   \n",
              "3                 -0.207294          1.346127          -1.312719  1.321303   \n",
              "4                  1.373936         -1.082342          -0.346076 -1.509848   \n",
              "5                  0.792151          0.657204          -0.207469  0.705274   \n",
              "\n",
              "            n_of_reviews  max_days_between_reviews  pagerank  \\\n",
              "cluster_ID                                                     \n",
              "1               1.007482                 -0.713532 -0.305503   \n",
              "2              -1.104972                 -0.954056  0.562551   \n",
              "3               0.537932                  1.884891  0.199406   \n",
              "4              -1.310554                 -0.062691 -1.719245   \n",
              "5               0.870112                 -0.154612  1.262791   \n",
              "\n",
              "            avg_5star_reviews  avg_days_between_reviews  \\\n",
              "cluster_ID                                                \n",
              "1                    0.446822                 -0.953102   \n",
              "2                   -1.162054                 -0.369221   \n",
              "3                    0.371724                  1.920086   \n",
              "4                   -1.103550                 -0.086888   \n",
              "5                    1.447059                 -0.510875   \n",
              "\n",
              "            stdev_days_between_reviews  avg_review_rating  std_review_len  \\\n",
              "cluster_ID                                                                  \n",
              "1                            -0.894197           0.407514       -1.052715   \n",
              "2                            -0.722083          -0.585912       -0.878354   \n",
              "3                             1.880321          -0.328384        1.658077   \n",
              "4                             0.100940          -1.205099        0.545031   \n",
              "5                            -0.364981           1.711882       -0.272040   \n",
              "\n",
              "            avg_1star_reviews  avg_helpful_reviews  min_days_between_reviews  \\\n",
              "cluster_ID                                                                     \n",
              "1                   -0.152997            -1.033721                       NaN   \n",
              "2                   -0.337226            -0.539321                       NaN   \n",
              "3                    1.089696             1.894304                       NaN   \n",
              "4                    1.022335            -0.177391                       NaN   \n",
              "5                   -1.621809            -0.143871                       NaN   \n",
              "\n",
              "            product_ID  p_fake  \n",
              "cluster_ID                      \n",
              "1                  141      13  \n",
              "2                  122     122  \n",
              "3                  162       0  \n",
              "4                  121     117  \n",
              "5                  136       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a9a593c-8cc9-461f-bdf3-6b39e9a68757\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clustering_coef</th>\n",
              "      <th>eigenvector_cent</th>\n",
              "      <th>avg_photo_reviews</th>\n",
              "      <th>w_degree</th>\n",
              "      <th>n_of_reviews</th>\n",
              "      <th>max_days_between_reviews</th>\n",
              "      <th>pagerank</th>\n",
              "      <th>avg_5star_reviews</th>\n",
              "      <th>avg_days_between_reviews</th>\n",
              "      <th>stdev_days_between_reviews</th>\n",
              "      <th>avg_review_rating</th>\n",
              "      <th>std_review_len</th>\n",
              "      <th>avg_1star_reviews</th>\n",
              "      <th>avg_helpful_reviews</th>\n",
              "      <th>min_days_between_reviews</th>\n",
              "      <th>product_ID</th>\n",
              "      <th>p_fake</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.467836</td>\n",
              "      <td>0.301230</td>\n",
              "      <td>1.761530</td>\n",
              "      <td>0.156124</td>\n",
              "      <td>1.007482</td>\n",
              "      <td>-0.713532</td>\n",
              "      <td>-0.305503</td>\n",
              "      <td>0.446822</td>\n",
              "      <td>-0.953102</td>\n",
              "      <td>-0.894197</td>\n",
              "      <td>0.407514</td>\n",
              "      <td>-1.052715</td>\n",
              "      <td>-0.152997</td>\n",
              "      <td>-1.033721</td>\n",
              "      <td>NaN</td>\n",
              "      <td>141</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.490958</td>\n",
              "      <td>-1.222219</td>\n",
              "      <td>0.104735</td>\n",
              "      <td>-0.672853</td>\n",
              "      <td>-1.104972</td>\n",
              "      <td>-0.954056</td>\n",
              "      <td>0.562551</td>\n",
              "      <td>-1.162054</td>\n",
              "      <td>-0.369221</td>\n",
              "      <td>-0.722083</td>\n",
              "      <td>-0.585912</td>\n",
              "      <td>-0.878354</td>\n",
              "      <td>-0.337226</td>\n",
              "      <td>-0.539321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.207294</td>\n",
              "      <td>1.346127</td>\n",
              "      <td>-1.312719</td>\n",
              "      <td>1.321303</td>\n",
              "      <td>0.537932</td>\n",
              "      <td>1.884891</td>\n",
              "      <td>0.199406</td>\n",
              "      <td>0.371724</td>\n",
              "      <td>1.920086</td>\n",
              "      <td>1.880321</td>\n",
              "      <td>-0.328384</td>\n",
              "      <td>1.658077</td>\n",
              "      <td>1.089696</td>\n",
              "      <td>1.894304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.373936</td>\n",
              "      <td>-1.082342</td>\n",
              "      <td>-0.346076</td>\n",
              "      <td>-1.509848</td>\n",
              "      <td>-1.310554</td>\n",
              "      <td>-0.062691</td>\n",
              "      <td>-1.719245</td>\n",
              "      <td>-1.103550</td>\n",
              "      <td>-0.086888</td>\n",
              "      <td>0.100940</td>\n",
              "      <td>-1.205099</td>\n",
              "      <td>0.545031</td>\n",
              "      <td>1.022335</td>\n",
              "      <td>-0.177391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>121</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.792151</td>\n",
              "      <td>0.657204</td>\n",
              "      <td>-0.207469</td>\n",
              "      <td>0.705274</td>\n",
              "      <td>0.870112</td>\n",
              "      <td>-0.154612</td>\n",
              "      <td>1.262791</td>\n",
              "      <td>1.447059</td>\n",
              "      <td>-0.510875</td>\n",
              "      <td>-0.364981</td>\n",
              "      <td>1.711882</td>\n",
              "      <td>-0.272040</td>\n",
              "      <td>-1.621809</td>\n",
              "      <td>-0.143871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a9a593c-8cc9-461f-bdf3-6b39e9a68757')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a9a593c-8cc9-461f-bdf3-6b39e9a68757 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a9a593c-8cc9-461f-bdf3-6b39e9a68757');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4516b2da-9c86-405a-80b5-ab9dee7f4e4e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4516b2da-9c86-405a-80b5-ab9dee7f4e4e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4516b2da-9c86-405a-80b5-ab9dee7f4e4e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b73b9586-eeae-4870-83ce-eca494fddd80\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('clusters_pt')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b73b9586-eeae-4870-83ce-eca494fddd80 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('clusters_pt');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clusters_pt",
              "summary": "{\n  \"name\": \"clusters_pt\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"cluster_ID\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clustering_coef\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.4909576617183518,\n        \"max\": 1.373936277813056,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.4909576617183518,\n          0.7921510411502567,\n          -0.20729384867823644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eigenvector_cent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.2222189066630935,\n        \"max\": 1.3461274786745063,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.2222189066630935,\n          0.6572040935786642,\n          1.3461274786745063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_photo_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.312718774126302,\n        \"max\": 1.7615299286366772,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.10473459970339291,\n          -0.20746940246625978,\n          -1.312718774126302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w_degree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.5098483837581564,\n        \"max\": 1.3213028656537635,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.6728525414031048,\n          0.7052739233108423,\n          1.3213028656537635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_of_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1180339887498947,\n        \"min\": -1.31055401487314,\n        \"max\": 1.0074823640164265,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.1049717636477112,\n          0.87011164263722,\n          0.5379317718672051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_days_between_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -0.9540561717660283,\n        \"max\": 1.8848908441871934,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.9540561717660283,\n          -0.15461151734635364,\n          1.8848908441871934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pagerank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1180339887498947,\n        \"min\": -1.7192445310993842,\n        \"max\": 1.2627905253999314,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5625508043093977,\n          1.2627905253999314,\n          0.19940620896969524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_5star_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.1620541169509568,\n        \"max\": 1.4470590142830253,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.1620541169509568,\n          1.4470590142830253,\n          0.3717235095956838\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_days_between_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -0.9531023388754924,\n        \"max\": 1.9200857441164543,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.36922062613633805,\n          -0.510875052269948,\n          1.9200857441164543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stdev_days_between_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -0.8941966732504683,\n        \"max\": 1.8803212126911097,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.7220834460916878,\n          -0.36498094464323766,\n          1.8803212126911097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_review_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1180339887498951,\n        \"min\": -1.2050994943514837,\n        \"max\": 1.7118816445301857,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.5859121326909376,\n          1.7118816445301857,\n          -0.3283838092133163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_review_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1180339887498947,\n        \"min\": -1.0527150876465428,\n        \"max\": 1.6580774556577758,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.8783538680118336,\n          -0.27203968193500266,\n          1.6580774556577758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_1star_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1180339887498947,\n        \"min\": -1.6218088361297267,\n        \"max\": 1.089695941507399,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.33722575332207505,\n          -1.6218088361297267,\n          1.089695941507399\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_helpful_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118033988749895,\n        \"min\": -1.0337209030899572,\n        \"max\": 1.894303949449403,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.5393210882507229,\n          -0.14387116820507126,\n          1.894303949449403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_days_between_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 121,\n        \"max\": 162,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_fake\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 4,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}